<p>
  Given two arrays <code>A</code> of <code>M</code> elements and <code>B</code> of <code>N</code> elements,
  each sorted in non-decreasing order and containing 32-bit floating point numbers, produce a single sorted
  output array <code>C</code> of <code>M + N</code> elements containing all values from <code>A</code>
  and <code>B</code> in non-decreasing order.
  The sequential merge algorithm processes elements one-by-one, but an efficient GPU implementation must
  determine each output element's origin independently â€” without a serial dependency chain.
</p>

<h2>Implementation Requirements</h2>
<ul>
  <li>Use only native features (external libraries are not permitted)</li>
  <li>The <code>solve</code> function signature must remain unchanged</li>
  <li>The final result must be stored in array <code>C</code></li>
</ul>

<h2>Example 1</h2>
<pre>
Input:
A = [1.0, 3.0, 5.0, 7.0]  (M = 4)
B = [2.0, 4.0, 6.0, 8.0]  (N = 4)

Output:
C = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]
</pre>

<h2>Example 2</h2>
<pre>
Input:
A = [1.0, 2.0, 3.0]  (M = 3)
B = [4.0]             (N = 1)

Output:
C = [1.0, 2.0, 3.0, 4.0]
</pre>

<h2>Constraints</h2>
<ul>
  <li>1 &le; <code>M</code>, <code>N</code> &le; 10,000,000</li>
  <li>All elements are 32-bit floating point numbers</li>
  <li>Input arrays are sorted in non-decreasing order and may contain duplicates</li>
  <li>Performance is measured with <code>M</code> = 10,000,000, <code>N</code> = 10,000,000</li>
</ul>
